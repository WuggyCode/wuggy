<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>wuggy.generators.wuggygenerator API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>wuggy.generators.wuggygenerator</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import codecs
import copy
import importlib
import inspect
import os
from collections import defaultdict, namedtuple
from csv import writer
from fractions import Fraction
from functools import wraps
from pathlib import Path
from shutil import rmtree
from sys import stdout
from time import time
from typing import Dict, Generator, Optional, Union
from urllib.request import urlopen
from warnings import warn

from ..plugins.baselanguageplugin import BaseLanguagePlugin
from ..utilities.bigramchain import BigramChain


def _loaded_language_plugin_required(func):
    &#34;&#34;&#34;
    Decorator used for regular Wuggy methods to ensure that a valid language plugin is loaded before execution.
    &#34;&#34;&#34;
    @wraps(func)
    def wrapper(*args, **kwargs):
        if not hasattr(args[0], &#39;language_plugin&#39;):
            raise Exception(
                &#34;This function cannot be called if no language plugin is loaded!&#34;)
        return func(*args, **kwargs)
    return wrapper


def _loaded_language_plugin_required_generator(func):
    &#34;&#34;&#34;
    Decorator used for Wuggy generator methods to ensure that a valid language plugin is loaded before execution.
    &#34;&#34;&#34;
    @wraps(func)
    def wrapper(*args, **kwargs):
        if not hasattr(args[0], &#39;language_plugin&#39;):
            raise Exception(
                &#34;The generator cannot be iterated if no language plugin is loaded!&#34;)
        gen = func(*args, **kwargs)
        for val in gen:
            yield val
    return wrapper


class WuggyGenerator():
    def __init__(self):
        self.bigramchain = None
        self.bigramchains = {}
        self.supported_official_language_plugin_names = [
            &#34;orthographic_dutch&#34;,
            &#34;orthographic_english&#34;,
            &#34;orthographic_french&#34;,
            &#34;orthographic_german&#34;,
            &#34;orthographic_italian&#34;,
            &#34;orthographic_polish&#34;,
            &#34;orthographic_serbian_cyrillic&#34;,
            &#34;orthographic_serbian_latin&#34;,
            &#34;orthographic_spanish&#34;,
            &#34;orthographic_vietnamese&#34;,
            &#34;phonetic_english_celex&#34;,
            &#34;phonetic_english_cmu&#34;,
            &#34;phonetic_french&#34;,
            &#34;phonetic_italian&#34;]
        self.__official_language_plugin_repository_url = &#34;https://raw.githubusercontent.com/Zenulous/wuggy_language_plugin_data/master/&#34;
        self.attribute_subchain = None
        self.frequency_subchain = None
        self.reference_sequence = None
        self.frequency_filter = None
        self.current_sequence = None
        self.output_mode = None
        self.supported_statistics = ()
        self.supported_attribute_filters = {}
        self.attribute_filters = {}
        self.default_attributes = []
        self.statistics = {}
        self.word_lexicon = defaultdict(list)
        self.neighbor_lexicon = []
        self.reference_statistics = {}
        self.stat_cache = {}
        self.sequence_cache = []
        self.difference_statistics = {}
        self.match_statistics = {}
        self.lookup_lexicon = {}

    def load(self, language_plugin_name: str,
             local_language_plugin: BaseLanguagePlugin = None) -&gt; None:
        &#34;&#34;&#34;
        Loads in a language plugin, if available, and stores the corresponding bigramchains.
        Parameters:
            language_plugin_name: must be the exact string of an official language plugin (see self.supported_official_language_plugin_names). If you are loading in a local plugin, the name can be anything as long as it does not conflict with an already loaded plugin name.

            local_language_plugin: must be a child class of BaseLanguagePlugin: see BaseLanguagePlugin for more information on how to create a custom language plugin.
        &#34;&#34;&#34;
        if local_language_plugin:
            # TODO: if someone does not pass a class INSTANCE, they get TypeError: &lt;class &#39;type&#39;&gt; is a built-in class, this is a vague error and probably should be abstracted
            self.language_plugin_data_path = os.path.dirname(
                inspect.getfile(local_language_plugin.__class__))
            self.language_plugin_name = language_plugin_name
            language_plugin = local_language_plugin

        if local_language_plugin is None:
            if language_plugin_name not in self.supported_official_language_plugin_names:
                raise ValueError(
                    &#34;This language is not officially supported by Wuggy at this moment. If this is a local plugin, pass the local_language_plugin&#34;)
            self.language_plugin_name = language_plugin_name
            language_plugins_folder_dirname = os.path.join(
                Path(__file__).parents[1], &#34;plugins&#34;, &#34;language_data&#34;)
            # TODO: move these os path checks under download method, only if autodownload is off
            if not os.path.exists(language_plugins_folder_dirname):
                os.makedirs(language_plugins_folder_dirname)
            self.language_plugin_data_path = os.path.join(
                language_plugins_folder_dirname, language_plugin_name)
            if not os.path.exists(self.language_plugin_data_path):
                os.makedirs(self.language_plugin_data_path)
                self.download_language_plugin(
                    language_plugin_name, self.language_plugin_data_path)
            # Official language plugins MUST have the class name &#34;OfficialLanguagePlugin&#34;!
            language_plugin = importlib.import_module(
                f&#34;.plugins.language_data.{language_plugin_name}.{language_plugin_name}&#34;,
                &#34;wuggy&#34;).OfficialLanguagePlugin()

        if language_plugin_name not in self.bigramchains:
            default_data_path = os.path.join(
                self.language_plugin_data_path, language_plugin.default_data)

            data_file = codecs.open(default_data_path, &#39;r&#39;, encoding=&#39;utf-8&#39;)
            self.bigramchains[self.language_plugin_name] = BigramChain(
                language_plugin)
            self.bigramchains[self.language_plugin_name].load(
                data_file)
        self.__activate(self.language_plugin_name)

    @staticmethod
    def remove_downloaded_language_plugins() -&gt; None:
        &#34;&#34;&#34;
        Removes all downloaded (official) language plugins.
        Useful to cleanup after an experiment or to remove corrupt language plugins.
        &#34;&#34;&#34;
        try:
            rmtree(os.path.join(Path(__file__).parents[1], &#34;plugins&#34;, &#34;language_data&#34;))
        except FileNotFoundError as err:
            raise FileNotFoundError(
                &#34;The official language plugin folder is already removed.&#34;) from err

    def download_language_plugin(
            self, language_plugin_name: str, path_to_save: str, auto_download=False) -&gt; None:
        &#34;&#34;&#34;
        Downloads and saves given language plugin to local storage from the corresponding official file repository.
        This method is called when you load in a language plugin automatically.
        If you need to ensure your Wuggy script works on any machine without user confirmation, execute this method with the
        Parameters:
            language_plugin_name: this is the name for the official language plugin you want to download. If the language name is not officially supported, the method will throw an error.

            path_to_save: absolute path to download the language plugin to.

            auto_download: determines whether Wuggy provides the user with a prompt to confirm downloading a language plugin.
        &#34;&#34;&#34;
        if language_plugin_name not in self.supported_official_language_plugin_names:
            raise ValueError(&#34;This language is not officially supported by Wuggy at this moment.&#34;)
        if not auto_download:
            while True:
                stdout.write(
                    f&#34;The language plugin {language_plugin_name} was not found in local storage. Do you allow Wuggy to download this plugin? [y/n]\n&#34;)
                choice = input().lower()
                if (not (choice.startswith(&#34;y&#34;) or choice.startswith(&#34;n&#34;))):
                    stdout.write(&#34;Please respond with &#39;y&#39; or &#39;n&#39;&#34;)
                elif choice.startswith(&#34;n&#34;):
                    raise ValueError(
                        &#34;User declined permission for Wuggy to download necessary language plugin.&#34;)
                else:
                    break
        warn(&#34;Wuggy is currently downloading this plugin for you from the official repository...&#34;)

        py_file_name = f&#34;{language_plugin_name}.py&#34;
        py_file = urlopen(
            f&#34;{self.__official_language_plugin_repository_url}/{language_plugin_name}/{py_file_name}&#34;)

        file = open(f&#39;{path_to_save}/{py_file_name}&#39;,
                    &#39;w&#39;, encoding=&#34;utf-8&#34;)
        # The current setup assumes that every official Wuggy language plugin use a single data file
        for line in py_file:
            file.write(line.decode(&#34;utf-8&#34;))
        data_file_name = f&#34;{language_plugin_name}.txt&#34;
        data_file = urlopen(
            f&#34;{self.__official_language_plugin_repository_url}/{language_plugin_name}/{data_file_name}&#34;)
        file = open(f&#39;{path_to_save}/{data_file_name}&#39;,
                    &#39;w&#39;, encoding=&#34;utf-8&#34;)

        for line in data_file:
            file.write(line.decode(&#34;utf-8&#34;))

    def __activate(self, name: str) -&gt; None:
        &#34;&#34;&#34;
        Activate a language plugin by setting the corresponding bigramchains and lexicon properties.
        This deactivates and garbage collects any previously activated language plugin.
        Should only be called internally, do not call on your own.
        &#34;&#34;&#34;
        if isinstance(name, type(codecs)):
            name = name.__name__
        self.bigramchain = self.bigramchains[name]
        self.language_plugin = self.bigramchain.language_plugin
        self.__load_neighbor_lexicon()
        self.__load_word_lexicon()
        self.__load_lookup_lexicon()
        self.supported_statistics = self.__get_statistics()
        self.supported_attribute_filters = self.__get_attributes()
        self.default_attributes = self.__get_default_attributes()
        self.current_language_plugin_name = name

    def __load_word_lexicon(self) -&gt; None:
        &#34;&#34;&#34;
        Loads the default word lexicon for the currently set language plugin.
        This is currently used internally by __activate only, do not call on your own.
        &#34;&#34;&#34;
        cutoff = 0
        data_file = codecs.open(
            &#34;%s/%s&#34; % (self.language_plugin_data_path, self.language_plugin.default_word_lexicon),
            &#39;r&#39;, encoding=&#34;utf-8&#34;)
        self.word_lexicon = defaultdict(list)
        lines = data_file.readlines()
        for line in lines:
            fields = line.strip().split(&#39;\t&#39;)
            word = fields[0]
            frequency_per_million = fields[-1]
            if float(frequency_per_million) &gt;= cutoff:
                self.word_lexicon[word[0], len(word)].append(word)
        data_file.close()

    def __load_neighbor_lexicon(self) -&gt; None:
        &#34;&#34;&#34;
        Loads the default neighbor word lexicon for the currently set language plugin.
        This is currently used internally by __activate only, do not call on your own.
        &#34;&#34;&#34;
        cutoff = 0
        data_file = codecs.open(
            &#34;%s/%s&#34; %
            (self.language_plugin_data_path,
             self.language_plugin.default_neighbor_lexicon),
            &#39;r&#39;,
            encoding=&#34;utf-8&#34;)
        self.neighbor_lexicon = []
        lines = data_file.readlines()
        for line in lines:
            fields = line.strip().split(&#39;\t&#39;)
            word = fields[0]
            frequency_per_million = fields[-1]
            if float(frequency_per_million) &gt;= cutoff:
                self.neighbor_lexicon.append(word)
        data_file.close()

    def __load_lookup_lexicon(self, data_file: bool = None) -&gt; None:
        &#34;&#34;&#34;
        Loads the default lookup word lexicon for the currently set language plugin.
        This is currently used internally by __activate only, do not call on your own.
        &#34;&#34;&#34;
        self.lookup_lexicon = {}
        if data_file is None:
            data_file = codecs.open(
                &#34;%s/%s&#34; %
                (self.language_plugin_data_path,
                 self.language_plugin.default_lookup_lexicon),
                &#39;r&#39;,
                encoding=&#34;utf-8&#34;)
        lines = data_file.readlines()
        for line in lines:
            fields = line.strip().split(self.language_plugin.separator)
            reference, representation = fields[0:2]
            self.lookup_lexicon[reference] = representation
        data_file.close()

    def lookup_reference_segments(self, reference: str) -&gt; Optional[str]:
        &#34;&#34;&#34;
        Look up a given reference (word) from the currently active lookup lexicon.
        Returns the segments of the found word, if the word is not found it returns None.
        This should be used before setting a word as a reference sequence.
        &#34;&#34;&#34;
        return self.lookup_lexicon.get(reference, None)

    def __get_attributes(self) -&gt; [namedtuple]:
        &#34;&#34;&#34;
        Returns a list of all attribute fields of the currently activated language plugin as a named tuple.
        This should only be used internally, read the property &#34;supported_attribute_filters&#34; instead.
        &#34;&#34;&#34;
        return self.language_plugin.Segment._fields

    def __get_default_attributes(self) -&gt; [str]:
        &#34;&#34;&#34;
        Returns a list of default attribute fields of the currently activated language plugin.
        This should only be used internally, read the property &#34;default_attributes&#34; instead.
        &#34;&#34;&#34;
        return self.language_plugin.default_fields

    @_loaded_language_plugin_required
    def set_reference_sequence(self, sequence: str) -&gt; None:
        &#34;&#34;&#34;
        Set the reference sequence.
        This is commonly used before generate methods in order to set the reference word for which pseudowords should be generated.
        &#34;&#34;&#34;
        self.reference_sequence = self.language_plugin.transform(
            sequence).representation
        self.reference_sequence_frequencies = self.bigramchain.get_frequencies(
            self.reference_sequence)
        self.__clear_stat_cache()
        for name in self.__get_statistics():
            function = eval(&#34;self.language_plugin.statistic_%s&#34; % (name))
            self.reference_statistics[name] = function(
                self, self.reference_sequence)

    def get_limit_frequencies(self, fields):
        # TODO: docstring and parameter type hint
        limits = []
        if tuple(fields) not in self.bigramchain.limit_frequencies:
            self.bigramchain.build_limit_frequencies(fields)
        for i in range(0, len(self.reference_sequence) - 1):
            subkey_a = (i, tuple(
                [self.reference_sequence[i].__getattribute__(field) for field in fields]))
            subkey_b = (i + 1,
                        tuple(
                            [self.reference_sequence[i + 1].__getattribute__(field)
                             for field in fields]))
            subkey = (subkey_a, subkey_b)
            try:
                limits.append(
                    self.bigramchain.limit_frequencies[tuple(fields)][subkey])
            except BaseException:
                limits.append([{max: 0, min: 0}])
        return limits

    def __get_statistics(self) -&gt; [str]:
        &#34;&#34;&#34;
        Lists all statistics supported by a given language plugin.
        This should only be used internally, read the property &#34;supported_statistics&#34; instead.
        &#34;&#34;&#34;
        names = [name for name in dir(
            self.language_plugin) if name.startswith(&#39;statistic&#39;)]
        return [name.replace(&#39;statistic_&#39;, &#39;&#39;) for name in names]

    def set_statistic(self, name: str) -&gt; None:
        &#34;&#34;&#34;
        Enable a statistic based on its name.
        &#34;&#34;&#34;
        if name not in self.supported_statistics:
            raise ValueError(f&#34;Statistic {name} is not supported.&#34;)
        self.statistics[name] = None

    def set_statistics(self, names: [str]) -&gt; None:
        &#34;&#34;&#34;
        Enables statistics based on their names.
        &#34;&#34;&#34;
        for name in names:
            if name not in self.supported_statistics:
                self.statistics = {}
                raise ValueError(f&#34;Statistic {name} is not supported.&#34;)
            self.statistics[name] = None

    def set_all_statistics(self) -&gt; None:
        &#34;&#34;&#34;
        Enable all statistics supported by the current active language plugin.
        Enabling all statistics increases word generation computation time, especially for statistics such as ned1.
        &#34;&#34;&#34;
        self.set_statistics(self.supported_statistics)

    def apply_statistics(self, sequence: str = None) -&gt; None:
        &#34;&#34;&#34;
        Apply all statistics which were set beforehand.
        &#34;&#34;&#34;
        if sequence is None:
            sequence = self.current_sequence
        for name in self.statistics:
            function = eval(&#34;self.language_plugin.statistic_%s&#34; % (name))
            if (sequence, name) in self.stat_cache:
                self.statistics[name] = self.stat_cache[(sequence, name)]
            else:
                self.statistics[name] = function(self, sequence)
                self.stat_cache[(sequence, name)] = self.statistics[name]
            if &#39;match&#39; in function.__dict__:
                self.match_statistics[name] = function.match(
                    self.statistics[name], self.reference_statistics[name])
            if &#39;difference&#39; in function.__dict__:
                self.difference_statistics[name] = function.difference(
                    self.statistics[name], self.reference_statistics[name])

    def clear_statistics(self) -&gt; None:
        &#34;&#34;&#34;
        Clear all the statistics set previously.
        &#34;&#34;&#34;
        self.statistics = {}

    def __clear_stat_cache(self) -&gt; None:
        &#34;&#34;&#34;
        Clears the statistics cache. Only used by Wuggy internally.
        &#34;&#34;&#34;
        self.stat_cache = {}

    def __clear_sequence_cache(self) -&gt; None:
        &#34;&#34;&#34;
        Clears the sequence cache. Only used by Wuggy internally.
        &#34;&#34;&#34;
        self.sequence_cache = []

    def list_output_modes(self) -&gt; [str]:
        &#34;&#34;&#34;
        List output modes of the currently activated language plugin.
        &#34;&#34;&#34;
        names = [name for name in dir(
            self.language_plugin) if name.startswith(&#39;output&#39;)]
        return [name.replace(&#39;output_&#39;, &#39;&#39;) for name in names]

    def set_output_mode(self, name: str) -&gt; None:
        &#34;&#34;&#34;
        Set an output mode supported by the currently activated language plugin.
        &#34;&#34;&#34;
        if name not in self.list_output_modes():
            raise ValueError(f&#34;Output mode {name} is not supported.&#34;)
        self.output_mode = eval(&#34;self.language_plugin.output_%s&#34; % (name))

    def set_attribute_filter(self, name: str) -&gt; None:
        &#34;&#34;&#34;
        Set an attribute filter supported by the currently activated language plugin.
        &#34;&#34;&#34;
        reference_sequence = self.reference_sequence
        if name not in self.supported_attribute_filters:
            raise ValueError(
                f&#34;Attribute filter {name} is not supported.&#34;)
        self.attribute_filters[name] = reference_sequence
        self.attribute_subchain = None

    def set_attribute_filters(self, names: [str]) -&gt; None:
        &#34;&#34;&#34;
        Set attribute filters supported by the currently activated language plugin.
        &#34;&#34;&#34;
        for name in names:
            self.set_attribute_filter(name)

    def __apply_attribute_filters(self) -&gt; None:
        &#34;&#34;&#34;
        Apply all set attribute filters.
        This is currently used by Wuggy internally, do not call on your own.
        &#34;&#34;&#34;
        for attribute, reference_sequence in self.attribute_filters.items():
            subchain = self.attribute_subchain if self.attribute_subchain is not None else self.bigramchain
            self.attribute_subchain = subchain.attribute_filter(
                reference_sequence, attribute)

    def clear_attribute_filters(self) -&gt; None:
        &#34;&#34;&#34;
        Remove all set attribute filters.
        &#34;&#34;&#34;
        self.attribute_filters = {}

    def set_frequency_filter(self, lower: int, upper: int) -&gt; None:
        &#34;&#34;&#34;
        Sets the frequency filter for concentric search.
        Stricter search (small values for lower and upper) result in faster word generation.
        &#34;&#34;&#34;
        self.frequency_filter = (self.reference_sequence, lower, upper)

    def clear_frequency_filter(self) -&gt; None:
        &#34;&#34;&#34;
        Clear the previously set frequency filter.
        &#34;&#34;&#34;
        self.frequency_filter = None
        self.frequency_subchain = None

    def apply_frequency_filter(self) -&gt; None:
        &#34;&#34;&#34;
        Apply the previously set frequency filter.
        &#34;&#34;&#34;
        if self.frequency_filter is None:
            raise Exception(&#34;No frequency filter was set&#34;)
        reference_sequence, lower, upper = self.frequency_filter
        subchain = self.attribute_subchain if self.attribute_subchain is not None else self.bigramchain
        self.frequency_subchain = subchain.frequency_filter(
            reference_sequence, lower, upper)

    @_loaded_language_plugin_required
    def generate_classic(
            self, input_sequences: [str],
            ncandidates_per_sequence: int = 10, max_search_time_per_sequence: int = 10,
            subsyllabic_segment_overlap_ratio: Union[Fraction, None] = Fraction(2, 3),
            match_subsyllabic_segment_length: bool = True, match_letter_length: bool = True,
            output_mode: str = &#34;plain&#34;, concentric_search: bool = True) -&gt; [Dict]:
        &#34;&#34;&#34;
        This is the classic method to generate pseudowords using Wuggy and can be called immediately after loading a language plugin.
        The defaults for this method are similar to those set in the legacy version of Wuggy, resulting in sensible pseudowords.
        This method returns a list of pseudoword matches, including all match and difference statistics (lexicality, ned1, old2, plain_length, deviation statistics...).
        Beware that this method always clears the sequence cache and all previously set filters.
        Parameters:
            input_sequences: these are the input sequences (words) for which you want to generate pseudowords.

            ncandidates_per_sequence: this is the n (maximum) amount of pseudowords you want to generate per input sequence.

            max_search_time_per_sequence: this is the maximum time in seconds to search for pseudowords per input sequence.

            subsyllabic_segment_overlap_ratio: this is the Fraction ratio for overlap between subsyllabic segments. The default ensures your pseudowords are very word-like but not easily identifiable as related to an existing word. If set to None, this constraint is not applied.

            match_subsyllabic_segment_length: determines whether the generated pseudowords must retain the same subsyllabic segment length as the respective input sequence.

            match_letter_length: determines whether the generated pseudowords must retain the same word length as the respective input sequence. This option is redundant if match_subsyllabic_segment_length is set to True.

            output_mode: output mode for pseudowords, constricted by the output modes supported by the currently loaded language plugin.

            concentric_search: enable/disable concentric search. Wuggy operates best and fastest when concentric search is enabled. First, the algorithm will try to generate candidates that exactly match the transition frequencies of the reference word. Then the maximal allowed deviation in transition frequencies will increase by powers of 2 (i.e., +/-2, +/-4, +/-8, etc.).
        .. include:: ../../documentation/wuggygenerator/generate_classic.md
        &#34;&#34;&#34;
        pseudoword_matches = []
        for input_sequence in input_sequences:
            pseudoword_matches.extend(
                self.__generate_classic_inner(
                    input_sequence,
                    ncandidates_per_sequence,
                    max_search_time_per_sequence,
                    subsyllabic_segment_overlap_ratio,
                    match_subsyllabic_segment_length,
                    match_letter_length, output_mode, concentric_search))
        return pseudoword_matches

    def __generate_classic_inner(
            self, input_sequence: str, ncandidates_per_sequence: int, max_search_time: int,
            subsyllabic_segment_overlap_ratio: Union[Fraction, None],
            match_subsyllabic_segment_length: bool, match_letter_length: bool, output_mode: str,
            concentric_search: bool = True):
        &#34;&#34;&#34;
        Inner method for generate_classic(), which outputs a list of pseudoword matches for an input sequence.
        Should only be used by WuggyGenerator internally.
        &#34;&#34;&#34;
        self.__clear_sequence_cache()
        self.clear_attribute_filters()
        self.clear_frequency_filter()
        input_sequence_segments = self.lookup_reference_segments(input_sequence)
        if input_sequence_segments is None:
            raise Exception(
                f&#34;Sequence {input_sequence} was not found in lexicon {self.current_language_plugin_name}&#34;)
        self.set_reference_sequence(input_sequence_segments)
        self.set_output_mode(output_mode)
        subchain = self.bigramchain
        starttime = time()
        pseudoword_matches = []
        frequency_exponent = 1
        if match_subsyllabic_segment_length:
            self.set_attribute_filter(&#34;segment_length&#34;)
            self.__apply_attribute_filters()
            subchain = self.attribute_subchain
        while True:
            if concentric_search:
                self.set_frequency_filter(
                    2**frequency_exponent, 2**frequency_exponent)
                frequency_exponent += 1
                self.apply_frequency_filter()
                subchain = self.frequency_subchain
            subchain = subchain.clean(len(self.reference_sequence) - 1)
            subchain.set_startkeys(self.reference_sequence)
            for sequence in subchain.generate():
                # Mandatory statistics before finding a suitable match
                self.clear_statistics()
                self.set_statistics([&#34;overlap_ratio&#34;, &#34;plain_length&#34;, &#34;lexicality&#34;])
                if (time() - starttime) &gt;= max_search_time:
                    return pseudoword_matches
                if self.language_plugin.output_plain(sequence) in self.sequence_cache:
                    continue
                self.current_sequence = sequence
                self.apply_statistics()
                if (not match_subsyllabic_segment_length and match_letter_length and self.difference_statistics[&#34;plain_length&#34;] != 0):
                    continue
                if (subsyllabic_segment_overlap_ratio is not None and self.statistics[&#34;overlap_ratio&#34;] !=
                        subsyllabic_segment_overlap_ratio):
                    continue
                if self.statistics[&#34;lexicality&#34;] == &#34;W&#34;:
                    continue
                # (Re)apply all statistics only if match is found: else search becomes unnecessarily slow
                self.set_all_statistics()
                self.apply_statistics()
                self.sequence_cache.append(
                    self.language_plugin.output_plain(sequence))
                match = {&#34;word&#34;: input_sequence,
                         &#34;segments&#34;: input_sequence_segments,
                         &#34;pseudoword&#34;: self.output_mode(sequence)}
                match.update({&#34;statistics&#34;: self.statistics,
                              &#34;difference_statistics&#34;: self.difference_statistics})

                pseudoword_matches.append(copy.deepcopy(match))
                if len(pseudoword_matches) &gt;= ncandidates_per_sequence:
                    return pseudoword_matches

    @_loaded_language_plugin_required_generator
    def generate_advanced(self, clear_cache: bool = True) -&gt; Union[Generator[str, None, None],
                                                                   Generator[tuple, None, None]]:
        &#34;&#34;&#34;
        Creates a custom generator which can be iterated to return generated pseudowords.
        The generator&#39;s settings, such as output statistics, should be set by you before calling this method.
        If attributes such as \&#34;output_mode\&#34; are not set, sensible defaults are used.
        Note that this method is for advanced users and may result in unexpected results if handled incorrectly.
        .. include:: ../../documentation/wuggygenerator/generate_advanced.md
        &#34;&#34;&#34;
        if clear_cache:
            self.__clear_sequence_cache()
        if self.output_mode is None:
            self.set_output_mode(&#34;plain&#34;)
        if len(self.attribute_filters) == 0 and self.frequency_subchain is None:
            subchain = self.bigramchain
        if len(self.attribute_filters) != 0:
            if self.attribute_subchain is None:
                self.__apply_attribute_filters()
            subchain = self.attribute_subchain
        if self.frequency_filter is not None:
            self.apply_frequency_filter()
            subchain = self.frequency_subchain
        if self.reference_sequence is not None:
            subchain = subchain.clean(len(self.reference_sequence) - 1)
            subchain.set_startkeys(self.reference_sequence)
        else:
            warn(
                &#34;No reference sequence was set. Ignore this message if this was intentional.&#34;)
            subchain.set_startkeys()
        for sequence in subchain.generate():
            if self.language_plugin.output_plain(sequence) in self.sequence_cache:
                pass
            else:
                self.sequence_cache.append(
                    self.language_plugin.output_plain(sequence))
                self.current_sequence = sequence
                self.apply_statistics()
                yield self.output_mode(sequence)

    def export_classic_pseudoword_matches_to_csv(
            self, pseudoword_matches: [Dict],
            csv_path: str) -&gt; None:
        &#34;&#34;&#34;
        Helper function to export generated pseudoword matches from generate_classic to CSV.
        The dictionairies from the matches are flattened before exporting to CSV.
        Parameters:

            pseudoword_matches: a dictionary of pseudoword matches retrieved from generate_classic
            csv_path: relative path to save csv file to (including the filename, e.g. ./pseudowords.csv)
        &#34;&#34;&#34;
        def get_csv_headers(dictionary: dict):
            headers = []

            def flatten_nested_dict_keys(dictionary: dict, parent_dict_key=None):
                for key, value in dictionary.items():
                    key = str(key)
                    if isinstance(value, dict):
                        flatten_nested_dict_keys(
                            value, (parent_dict_key + &#34;_&#34; + key if parent_dict_key else key))
                    else:
                        if parent_dict_key:
                            headers.append((parent_dict_key + &#34;_&#34; + key))
                        else:
                            headers.append(key)
                return headers
            flatten_nested_dict_keys(dictionary)
            return headers

        def get_values_from_nested_dictionary(dictionary: dict):
            dict_vals = []

            def flatten_nested_dict_values(dictionary: dict):
                for value in dictionary.values():
                    if isinstance(value, dict):
                        flatten_nested_dict_values(value)
                    else:
                        dict_vals.append(value)
            flatten_nested_dict_values(dictionary)
            return dict_vals

        with open(csv_path, &#34;w&#34;, newline=&#39;&#39;) as csvfile:
            file_writer = writer(csvfile)
            file_writer.writerow(get_csv_headers(pseudoword_matches[0]))
            for match in pseudoword_matches:
                file_writer.writerow(get_values_from_nested_dictionary(match))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator"><code class="flex name class">
<span>class <span class="ident">WuggyGenerator</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class WuggyGenerator():
    def __init__(self):
        self.bigramchain = None
        self.bigramchains = {}
        self.supported_official_language_plugin_names = [
            &#34;orthographic_dutch&#34;,
            &#34;orthographic_english&#34;,
            &#34;orthographic_french&#34;,
            &#34;orthographic_german&#34;,
            &#34;orthographic_italian&#34;,
            &#34;orthographic_polish&#34;,
            &#34;orthographic_serbian_cyrillic&#34;,
            &#34;orthographic_serbian_latin&#34;,
            &#34;orthographic_spanish&#34;,
            &#34;orthographic_vietnamese&#34;,
            &#34;phonetic_english_celex&#34;,
            &#34;phonetic_english_cmu&#34;,
            &#34;phonetic_french&#34;,
            &#34;phonetic_italian&#34;]
        self.__official_language_plugin_repository_url = &#34;https://raw.githubusercontent.com/Zenulous/wuggy_language_plugin_data/master/&#34;
        self.attribute_subchain = None
        self.frequency_subchain = None
        self.reference_sequence = None
        self.frequency_filter = None
        self.current_sequence = None
        self.output_mode = None
        self.supported_statistics = ()
        self.supported_attribute_filters = {}
        self.attribute_filters = {}
        self.default_attributes = []
        self.statistics = {}
        self.word_lexicon = defaultdict(list)
        self.neighbor_lexicon = []
        self.reference_statistics = {}
        self.stat_cache = {}
        self.sequence_cache = []
        self.difference_statistics = {}
        self.match_statistics = {}
        self.lookup_lexicon = {}

    def load(self, language_plugin_name: str,
             local_language_plugin: BaseLanguagePlugin = None) -&gt; None:
        &#34;&#34;&#34;
        Loads in a language plugin, if available, and stores the corresponding bigramchains.
        Parameters:
            language_plugin_name: must be the exact string of an official language plugin (see self.supported_official_language_plugin_names). If you are loading in a local plugin, the name can be anything as long as it does not conflict with an already loaded plugin name.

            local_language_plugin: must be a child class of BaseLanguagePlugin: see BaseLanguagePlugin for more information on how to create a custom language plugin.
        &#34;&#34;&#34;
        if local_language_plugin:
            # TODO: if someone does not pass a class INSTANCE, they get TypeError: &lt;class &#39;type&#39;&gt; is a built-in class, this is a vague error and probably should be abstracted
            self.language_plugin_data_path = os.path.dirname(
                inspect.getfile(local_language_plugin.__class__))
            self.language_plugin_name = language_plugin_name
            language_plugin = local_language_plugin

        if local_language_plugin is None:
            if language_plugin_name not in self.supported_official_language_plugin_names:
                raise ValueError(
                    &#34;This language is not officially supported by Wuggy at this moment. If this is a local plugin, pass the local_language_plugin&#34;)
            self.language_plugin_name = language_plugin_name
            language_plugins_folder_dirname = os.path.join(
                Path(__file__).parents[1], &#34;plugins&#34;, &#34;language_data&#34;)
            # TODO: move these os path checks under download method, only if autodownload is off
            if not os.path.exists(language_plugins_folder_dirname):
                os.makedirs(language_plugins_folder_dirname)
            self.language_plugin_data_path = os.path.join(
                language_plugins_folder_dirname, language_plugin_name)
            if not os.path.exists(self.language_plugin_data_path):
                os.makedirs(self.language_plugin_data_path)
                self.download_language_plugin(
                    language_plugin_name, self.language_plugin_data_path)
            # Official language plugins MUST have the class name &#34;OfficialLanguagePlugin&#34;!
            language_plugin = importlib.import_module(
                f&#34;.plugins.language_data.{language_plugin_name}.{language_plugin_name}&#34;,
                &#34;wuggy&#34;).OfficialLanguagePlugin()

        if language_plugin_name not in self.bigramchains:
            default_data_path = os.path.join(
                self.language_plugin_data_path, language_plugin.default_data)

            data_file = codecs.open(default_data_path, &#39;r&#39;, encoding=&#39;utf-8&#39;)
            self.bigramchains[self.language_plugin_name] = BigramChain(
                language_plugin)
            self.bigramchains[self.language_plugin_name].load(
                data_file)
        self.__activate(self.language_plugin_name)

    @staticmethod
    def remove_downloaded_language_plugins() -&gt; None:
        &#34;&#34;&#34;
        Removes all downloaded (official) language plugins.
        Useful to cleanup after an experiment or to remove corrupt language plugins.
        &#34;&#34;&#34;
        try:
            rmtree(os.path.join(Path(__file__).parents[1], &#34;plugins&#34;, &#34;language_data&#34;))
        except FileNotFoundError as err:
            raise FileNotFoundError(
                &#34;The official language plugin folder is already removed.&#34;) from err

    def download_language_plugin(
            self, language_plugin_name: str, path_to_save: str, auto_download=False) -&gt; None:
        &#34;&#34;&#34;
        Downloads and saves given language plugin to local storage from the corresponding official file repository.
        This method is called when you load in a language plugin automatically.
        If you need to ensure your Wuggy script works on any machine without user confirmation, execute this method with the
        Parameters:
            language_plugin_name: this is the name for the official language plugin you want to download. If the language name is not officially supported, the method will throw an error.

            path_to_save: absolute path to download the language plugin to.

            auto_download: determines whether Wuggy provides the user with a prompt to confirm downloading a language plugin.
        &#34;&#34;&#34;
        if language_plugin_name not in self.supported_official_language_plugin_names:
            raise ValueError(&#34;This language is not officially supported by Wuggy at this moment.&#34;)
        if not auto_download:
            while True:
                stdout.write(
                    f&#34;The language plugin {language_plugin_name} was not found in local storage. Do you allow Wuggy to download this plugin? [y/n]\n&#34;)
                choice = input().lower()
                if (not (choice.startswith(&#34;y&#34;) or choice.startswith(&#34;n&#34;))):
                    stdout.write(&#34;Please respond with &#39;y&#39; or &#39;n&#39;&#34;)
                elif choice.startswith(&#34;n&#34;):
                    raise ValueError(
                        &#34;User declined permission for Wuggy to download necessary language plugin.&#34;)
                else:
                    break
        warn(&#34;Wuggy is currently downloading this plugin for you from the official repository...&#34;)

        py_file_name = f&#34;{language_plugin_name}.py&#34;
        py_file = urlopen(
            f&#34;{self.__official_language_plugin_repository_url}/{language_plugin_name}/{py_file_name}&#34;)

        file = open(f&#39;{path_to_save}/{py_file_name}&#39;,
                    &#39;w&#39;, encoding=&#34;utf-8&#34;)
        # The current setup assumes that every official Wuggy language plugin use a single data file
        for line in py_file:
            file.write(line.decode(&#34;utf-8&#34;))
        data_file_name = f&#34;{language_plugin_name}.txt&#34;
        data_file = urlopen(
            f&#34;{self.__official_language_plugin_repository_url}/{language_plugin_name}/{data_file_name}&#34;)
        file = open(f&#39;{path_to_save}/{data_file_name}&#39;,
                    &#39;w&#39;, encoding=&#34;utf-8&#34;)

        for line in data_file:
            file.write(line.decode(&#34;utf-8&#34;))

    def __activate(self, name: str) -&gt; None:
        &#34;&#34;&#34;
        Activate a language plugin by setting the corresponding bigramchains and lexicon properties.
        This deactivates and garbage collects any previously activated language plugin.
        Should only be called internally, do not call on your own.
        &#34;&#34;&#34;
        if isinstance(name, type(codecs)):
            name = name.__name__
        self.bigramchain = self.bigramchains[name]
        self.language_plugin = self.bigramchain.language_plugin
        self.__load_neighbor_lexicon()
        self.__load_word_lexicon()
        self.__load_lookup_lexicon()
        self.supported_statistics = self.__get_statistics()
        self.supported_attribute_filters = self.__get_attributes()
        self.default_attributes = self.__get_default_attributes()
        self.current_language_plugin_name = name

    def __load_word_lexicon(self) -&gt; None:
        &#34;&#34;&#34;
        Loads the default word lexicon for the currently set language plugin.
        This is currently used internally by __activate only, do not call on your own.
        &#34;&#34;&#34;
        cutoff = 0
        data_file = codecs.open(
            &#34;%s/%s&#34; % (self.language_plugin_data_path, self.language_plugin.default_word_lexicon),
            &#39;r&#39;, encoding=&#34;utf-8&#34;)
        self.word_lexicon = defaultdict(list)
        lines = data_file.readlines()
        for line in lines:
            fields = line.strip().split(&#39;\t&#39;)
            word = fields[0]
            frequency_per_million = fields[-1]
            if float(frequency_per_million) &gt;= cutoff:
                self.word_lexicon[word[0], len(word)].append(word)
        data_file.close()

    def __load_neighbor_lexicon(self) -&gt; None:
        &#34;&#34;&#34;
        Loads the default neighbor word lexicon for the currently set language plugin.
        This is currently used internally by __activate only, do not call on your own.
        &#34;&#34;&#34;
        cutoff = 0
        data_file = codecs.open(
            &#34;%s/%s&#34; %
            (self.language_plugin_data_path,
             self.language_plugin.default_neighbor_lexicon),
            &#39;r&#39;,
            encoding=&#34;utf-8&#34;)
        self.neighbor_lexicon = []
        lines = data_file.readlines()
        for line in lines:
            fields = line.strip().split(&#39;\t&#39;)
            word = fields[0]
            frequency_per_million = fields[-1]
            if float(frequency_per_million) &gt;= cutoff:
                self.neighbor_lexicon.append(word)
        data_file.close()

    def __load_lookup_lexicon(self, data_file: bool = None) -&gt; None:
        &#34;&#34;&#34;
        Loads the default lookup word lexicon for the currently set language plugin.
        This is currently used internally by __activate only, do not call on your own.
        &#34;&#34;&#34;
        self.lookup_lexicon = {}
        if data_file is None:
            data_file = codecs.open(
                &#34;%s/%s&#34; %
                (self.language_plugin_data_path,
                 self.language_plugin.default_lookup_lexicon),
                &#39;r&#39;,
                encoding=&#34;utf-8&#34;)
        lines = data_file.readlines()
        for line in lines:
            fields = line.strip().split(self.language_plugin.separator)
            reference, representation = fields[0:2]
            self.lookup_lexicon[reference] = representation
        data_file.close()

    def lookup_reference_segments(self, reference: str) -&gt; Optional[str]:
        &#34;&#34;&#34;
        Look up a given reference (word) from the currently active lookup lexicon.
        Returns the segments of the found word, if the word is not found it returns None.
        This should be used before setting a word as a reference sequence.
        &#34;&#34;&#34;
        return self.lookup_lexicon.get(reference, None)

    def __get_attributes(self) -&gt; [namedtuple]:
        &#34;&#34;&#34;
        Returns a list of all attribute fields of the currently activated language plugin as a named tuple.
        This should only be used internally, read the property &#34;supported_attribute_filters&#34; instead.
        &#34;&#34;&#34;
        return self.language_plugin.Segment._fields

    def __get_default_attributes(self) -&gt; [str]:
        &#34;&#34;&#34;
        Returns a list of default attribute fields of the currently activated language plugin.
        This should only be used internally, read the property &#34;default_attributes&#34; instead.
        &#34;&#34;&#34;
        return self.language_plugin.default_fields

    @_loaded_language_plugin_required
    def set_reference_sequence(self, sequence: str) -&gt; None:
        &#34;&#34;&#34;
        Set the reference sequence.
        This is commonly used before generate methods in order to set the reference word for which pseudowords should be generated.
        &#34;&#34;&#34;
        self.reference_sequence = self.language_plugin.transform(
            sequence).representation
        self.reference_sequence_frequencies = self.bigramchain.get_frequencies(
            self.reference_sequence)
        self.__clear_stat_cache()
        for name in self.__get_statistics():
            function = eval(&#34;self.language_plugin.statistic_%s&#34; % (name))
            self.reference_statistics[name] = function(
                self, self.reference_sequence)

    def get_limit_frequencies(self, fields):
        # TODO: docstring and parameter type hint
        limits = []
        if tuple(fields) not in self.bigramchain.limit_frequencies:
            self.bigramchain.build_limit_frequencies(fields)
        for i in range(0, len(self.reference_sequence) - 1):
            subkey_a = (i, tuple(
                [self.reference_sequence[i].__getattribute__(field) for field in fields]))
            subkey_b = (i + 1,
                        tuple(
                            [self.reference_sequence[i + 1].__getattribute__(field)
                             for field in fields]))
            subkey = (subkey_a, subkey_b)
            try:
                limits.append(
                    self.bigramchain.limit_frequencies[tuple(fields)][subkey])
            except BaseException:
                limits.append([{max: 0, min: 0}])
        return limits

    def __get_statistics(self) -&gt; [str]:
        &#34;&#34;&#34;
        Lists all statistics supported by a given language plugin.
        This should only be used internally, read the property &#34;supported_statistics&#34; instead.
        &#34;&#34;&#34;
        names = [name for name in dir(
            self.language_plugin) if name.startswith(&#39;statistic&#39;)]
        return [name.replace(&#39;statistic_&#39;, &#39;&#39;) for name in names]

    def set_statistic(self, name: str) -&gt; None:
        &#34;&#34;&#34;
        Enable a statistic based on its name.
        &#34;&#34;&#34;
        if name not in self.supported_statistics:
            raise ValueError(f&#34;Statistic {name} is not supported.&#34;)
        self.statistics[name] = None

    def set_statistics(self, names: [str]) -&gt; None:
        &#34;&#34;&#34;
        Enables statistics based on their names.
        &#34;&#34;&#34;
        for name in names:
            if name not in self.supported_statistics:
                self.statistics = {}
                raise ValueError(f&#34;Statistic {name} is not supported.&#34;)
            self.statistics[name] = None

    def set_all_statistics(self) -&gt; None:
        &#34;&#34;&#34;
        Enable all statistics supported by the current active language plugin.
        Enabling all statistics increases word generation computation time, especially for statistics such as ned1.
        &#34;&#34;&#34;
        self.set_statistics(self.supported_statistics)

    def apply_statistics(self, sequence: str = None) -&gt; None:
        &#34;&#34;&#34;
        Apply all statistics which were set beforehand.
        &#34;&#34;&#34;
        if sequence is None:
            sequence = self.current_sequence
        for name in self.statistics:
            function = eval(&#34;self.language_plugin.statistic_%s&#34; % (name))
            if (sequence, name) in self.stat_cache:
                self.statistics[name] = self.stat_cache[(sequence, name)]
            else:
                self.statistics[name] = function(self, sequence)
                self.stat_cache[(sequence, name)] = self.statistics[name]
            if &#39;match&#39; in function.__dict__:
                self.match_statistics[name] = function.match(
                    self.statistics[name], self.reference_statistics[name])
            if &#39;difference&#39; in function.__dict__:
                self.difference_statistics[name] = function.difference(
                    self.statistics[name], self.reference_statistics[name])

    def clear_statistics(self) -&gt; None:
        &#34;&#34;&#34;
        Clear all the statistics set previously.
        &#34;&#34;&#34;
        self.statistics = {}

    def __clear_stat_cache(self) -&gt; None:
        &#34;&#34;&#34;
        Clears the statistics cache. Only used by Wuggy internally.
        &#34;&#34;&#34;
        self.stat_cache = {}

    def __clear_sequence_cache(self) -&gt; None:
        &#34;&#34;&#34;
        Clears the sequence cache. Only used by Wuggy internally.
        &#34;&#34;&#34;
        self.sequence_cache = []

    def list_output_modes(self) -&gt; [str]:
        &#34;&#34;&#34;
        List output modes of the currently activated language plugin.
        &#34;&#34;&#34;
        names = [name for name in dir(
            self.language_plugin) if name.startswith(&#39;output&#39;)]
        return [name.replace(&#39;output_&#39;, &#39;&#39;) for name in names]

    def set_output_mode(self, name: str) -&gt; None:
        &#34;&#34;&#34;
        Set an output mode supported by the currently activated language plugin.
        &#34;&#34;&#34;
        if name not in self.list_output_modes():
            raise ValueError(f&#34;Output mode {name} is not supported.&#34;)
        self.output_mode = eval(&#34;self.language_plugin.output_%s&#34; % (name))

    def set_attribute_filter(self, name: str) -&gt; None:
        &#34;&#34;&#34;
        Set an attribute filter supported by the currently activated language plugin.
        &#34;&#34;&#34;
        reference_sequence = self.reference_sequence
        if name not in self.supported_attribute_filters:
            raise ValueError(
                f&#34;Attribute filter {name} is not supported.&#34;)
        self.attribute_filters[name] = reference_sequence
        self.attribute_subchain = None

    def set_attribute_filters(self, names: [str]) -&gt; None:
        &#34;&#34;&#34;
        Set attribute filters supported by the currently activated language plugin.
        &#34;&#34;&#34;
        for name in names:
            self.set_attribute_filter(name)

    def __apply_attribute_filters(self) -&gt; None:
        &#34;&#34;&#34;
        Apply all set attribute filters.
        This is currently used by Wuggy internally, do not call on your own.
        &#34;&#34;&#34;
        for attribute, reference_sequence in self.attribute_filters.items():
            subchain = self.attribute_subchain if self.attribute_subchain is not None else self.bigramchain
            self.attribute_subchain = subchain.attribute_filter(
                reference_sequence, attribute)

    def clear_attribute_filters(self) -&gt; None:
        &#34;&#34;&#34;
        Remove all set attribute filters.
        &#34;&#34;&#34;
        self.attribute_filters = {}

    def set_frequency_filter(self, lower: int, upper: int) -&gt; None:
        &#34;&#34;&#34;
        Sets the frequency filter for concentric search.
        Stricter search (small values for lower and upper) result in faster word generation.
        &#34;&#34;&#34;
        self.frequency_filter = (self.reference_sequence, lower, upper)

    def clear_frequency_filter(self) -&gt; None:
        &#34;&#34;&#34;
        Clear the previously set frequency filter.
        &#34;&#34;&#34;
        self.frequency_filter = None
        self.frequency_subchain = None

    def apply_frequency_filter(self) -&gt; None:
        &#34;&#34;&#34;
        Apply the previously set frequency filter.
        &#34;&#34;&#34;
        if self.frequency_filter is None:
            raise Exception(&#34;No frequency filter was set&#34;)
        reference_sequence, lower, upper = self.frequency_filter
        subchain = self.attribute_subchain if self.attribute_subchain is not None else self.bigramchain
        self.frequency_subchain = subchain.frequency_filter(
            reference_sequence, lower, upper)

    @_loaded_language_plugin_required
    def generate_classic(
            self, input_sequences: [str],
            ncandidates_per_sequence: int = 10, max_search_time_per_sequence: int = 10,
            subsyllabic_segment_overlap_ratio: Union[Fraction, None] = Fraction(2, 3),
            match_subsyllabic_segment_length: bool = True, match_letter_length: bool = True,
            output_mode: str = &#34;plain&#34;, concentric_search: bool = True) -&gt; [Dict]:
        &#34;&#34;&#34;
        This is the classic method to generate pseudowords using Wuggy and can be called immediately after loading a language plugin.
        The defaults for this method are similar to those set in the legacy version of Wuggy, resulting in sensible pseudowords.
        This method returns a list of pseudoword matches, including all match and difference statistics (lexicality, ned1, old2, plain_length, deviation statistics...).
        Beware that this method always clears the sequence cache and all previously set filters.
        Parameters:
            input_sequences: these are the input sequences (words) for which you want to generate pseudowords.

            ncandidates_per_sequence: this is the n (maximum) amount of pseudowords you want to generate per input sequence.

            max_search_time_per_sequence: this is the maximum time in seconds to search for pseudowords per input sequence.

            subsyllabic_segment_overlap_ratio: this is the Fraction ratio for overlap between subsyllabic segments. The default ensures your pseudowords are very word-like but not easily identifiable as related to an existing word. If set to None, this constraint is not applied.

            match_subsyllabic_segment_length: determines whether the generated pseudowords must retain the same subsyllabic segment length as the respective input sequence.

            match_letter_length: determines whether the generated pseudowords must retain the same word length as the respective input sequence. This option is redundant if match_subsyllabic_segment_length is set to True.

            output_mode: output mode for pseudowords, constricted by the output modes supported by the currently loaded language plugin.

            concentric_search: enable/disable concentric search. Wuggy operates best and fastest when concentric search is enabled. First, the algorithm will try to generate candidates that exactly match the transition frequencies of the reference word. Then the maximal allowed deviation in transition frequencies will increase by powers of 2 (i.e., +/-2, +/-4, +/-8, etc.).
        .. include:: ../../documentation/wuggygenerator/generate_classic.md
        &#34;&#34;&#34;
        pseudoword_matches = []
        for input_sequence in input_sequences:
            pseudoword_matches.extend(
                self.__generate_classic_inner(
                    input_sequence,
                    ncandidates_per_sequence,
                    max_search_time_per_sequence,
                    subsyllabic_segment_overlap_ratio,
                    match_subsyllabic_segment_length,
                    match_letter_length, output_mode, concentric_search))
        return pseudoword_matches

    def __generate_classic_inner(
            self, input_sequence: str, ncandidates_per_sequence: int, max_search_time: int,
            subsyllabic_segment_overlap_ratio: Union[Fraction, None],
            match_subsyllabic_segment_length: bool, match_letter_length: bool, output_mode: str,
            concentric_search: bool = True):
        &#34;&#34;&#34;
        Inner method for generate_classic(), which outputs a list of pseudoword matches for an input sequence.
        Should only be used by WuggyGenerator internally.
        &#34;&#34;&#34;
        self.__clear_sequence_cache()
        self.clear_attribute_filters()
        self.clear_frequency_filter()
        input_sequence_segments = self.lookup_reference_segments(input_sequence)
        if input_sequence_segments is None:
            raise Exception(
                f&#34;Sequence {input_sequence} was not found in lexicon {self.current_language_plugin_name}&#34;)
        self.set_reference_sequence(input_sequence_segments)
        self.set_output_mode(output_mode)
        subchain = self.bigramchain
        starttime = time()
        pseudoword_matches = []
        frequency_exponent = 1
        if match_subsyllabic_segment_length:
            self.set_attribute_filter(&#34;segment_length&#34;)
            self.__apply_attribute_filters()
            subchain = self.attribute_subchain
        while True:
            if concentric_search:
                self.set_frequency_filter(
                    2**frequency_exponent, 2**frequency_exponent)
                frequency_exponent += 1
                self.apply_frequency_filter()
                subchain = self.frequency_subchain
            subchain = subchain.clean(len(self.reference_sequence) - 1)
            subchain.set_startkeys(self.reference_sequence)
            for sequence in subchain.generate():
                # Mandatory statistics before finding a suitable match
                self.clear_statistics()
                self.set_statistics([&#34;overlap_ratio&#34;, &#34;plain_length&#34;, &#34;lexicality&#34;])
                if (time() - starttime) &gt;= max_search_time:
                    return pseudoword_matches
                if self.language_plugin.output_plain(sequence) in self.sequence_cache:
                    continue
                self.current_sequence = sequence
                self.apply_statistics()
                if (not match_subsyllabic_segment_length and match_letter_length and self.difference_statistics[&#34;plain_length&#34;] != 0):
                    continue
                if (subsyllabic_segment_overlap_ratio is not None and self.statistics[&#34;overlap_ratio&#34;] !=
                        subsyllabic_segment_overlap_ratio):
                    continue
                if self.statistics[&#34;lexicality&#34;] == &#34;W&#34;:
                    continue
                # (Re)apply all statistics only if match is found: else search becomes unnecessarily slow
                self.set_all_statistics()
                self.apply_statistics()
                self.sequence_cache.append(
                    self.language_plugin.output_plain(sequence))
                match = {&#34;word&#34;: input_sequence,
                         &#34;segments&#34;: input_sequence_segments,
                         &#34;pseudoword&#34;: self.output_mode(sequence)}
                match.update({&#34;statistics&#34;: self.statistics,
                              &#34;difference_statistics&#34;: self.difference_statistics})

                pseudoword_matches.append(copy.deepcopy(match))
                if len(pseudoword_matches) &gt;= ncandidates_per_sequence:
                    return pseudoword_matches

    @_loaded_language_plugin_required_generator
    def generate_advanced(self, clear_cache: bool = True) -&gt; Union[Generator[str, None, None],
                                                                   Generator[tuple, None, None]]:
        &#34;&#34;&#34;
        Creates a custom generator which can be iterated to return generated pseudowords.
        The generator&#39;s settings, such as output statistics, should be set by you before calling this method.
        If attributes such as \&#34;output_mode\&#34; are not set, sensible defaults are used.
        Note that this method is for advanced users and may result in unexpected results if handled incorrectly.
        .. include:: ../../documentation/wuggygenerator/generate_advanced.md
        &#34;&#34;&#34;
        if clear_cache:
            self.__clear_sequence_cache()
        if self.output_mode is None:
            self.set_output_mode(&#34;plain&#34;)
        if len(self.attribute_filters) == 0 and self.frequency_subchain is None:
            subchain = self.bigramchain
        if len(self.attribute_filters) != 0:
            if self.attribute_subchain is None:
                self.__apply_attribute_filters()
            subchain = self.attribute_subchain
        if self.frequency_filter is not None:
            self.apply_frequency_filter()
            subchain = self.frequency_subchain
        if self.reference_sequence is not None:
            subchain = subchain.clean(len(self.reference_sequence) - 1)
            subchain.set_startkeys(self.reference_sequence)
        else:
            warn(
                &#34;No reference sequence was set. Ignore this message if this was intentional.&#34;)
            subchain.set_startkeys()
        for sequence in subchain.generate():
            if self.language_plugin.output_plain(sequence) in self.sequence_cache:
                pass
            else:
                self.sequence_cache.append(
                    self.language_plugin.output_plain(sequence))
                self.current_sequence = sequence
                self.apply_statistics()
                yield self.output_mode(sequence)

    def export_classic_pseudoword_matches_to_csv(
            self, pseudoword_matches: [Dict],
            csv_path: str) -&gt; None:
        &#34;&#34;&#34;
        Helper function to export generated pseudoword matches from generate_classic to CSV.
        The dictionairies from the matches are flattened before exporting to CSV.
        Parameters:

            pseudoword_matches: a dictionary of pseudoword matches retrieved from generate_classic
            csv_path: relative path to save csv file to (including the filename, e.g. ./pseudowords.csv)
        &#34;&#34;&#34;
        def get_csv_headers(dictionary: dict):
            headers = []

            def flatten_nested_dict_keys(dictionary: dict, parent_dict_key=None):
                for key, value in dictionary.items():
                    key = str(key)
                    if isinstance(value, dict):
                        flatten_nested_dict_keys(
                            value, (parent_dict_key + &#34;_&#34; + key if parent_dict_key else key))
                    else:
                        if parent_dict_key:
                            headers.append((parent_dict_key + &#34;_&#34; + key))
                        else:
                            headers.append(key)
                return headers
            flatten_nested_dict_keys(dictionary)
            return headers

        def get_values_from_nested_dictionary(dictionary: dict):
            dict_vals = []

            def flatten_nested_dict_values(dictionary: dict):
                for value in dictionary.values():
                    if isinstance(value, dict):
                        flatten_nested_dict_values(value)
                    else:
                        dict_vals.append(value)
            flatten_nested_dict_values(dictionary)
            return dict_vals

        with open(csv_path, &#34;w&#34;, newline=&#39;&#39;) as csvfile:
            file_writer = writer(csvfile)
            file_writer.writerow(get_csv_headers(pseudoword_matches[0]))
            for match in pseudoword_matches:
                file_writer.writerow(get_values_from_nested_dictionary(match))</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.remove_downloaded_language_plugins"><code class="name flex">
<span>def <span class="ident">remove_downloaded_language_plugins</span></span>(<span>) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Removes all downloaded (official) language plugins.
Useful to cleanup after an experiment or to remove corrupt language plugins.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def remove_downloaded_language_plugins() -&gt; None:
    &#34;&#34;&#34;
    Removes all downloaded (official) language plugins.
    Useful to cleanup after an experiment or to remove corrupt language plugins.
    &#34;&#34;&#34;
    try:
        rmtree(os.path.join(Path(__file__).parents[1], &#34;plugins&#34;, &#34;language_data&#34;))
    except FileNotFoundError as err:
        raise FileNotFoundError(
            &#34;The official language plugin folder is already removed.&#34;) from err</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.apply_frequency_filter"><code class="name flex">
<span>def <span class="ident">apply_frequency_filter</span></span>(<span>self) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Apply the previously set frequency filter.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_frequency_filter(self) -&gt; None:
    &#34;&#34;&#34;
    Apply the previously set frequency filter.
    &#34;&#34;&#34;
    if self.frequency_filter is None:
        raise Exception(&#34;No frequency filter was set&#34;)
    reference_sequence, lower, upper = self.frequency_filter
    subchain = self.attribute_subchain if self.attribute_subchain is not None else self.bigramchain
    self.frequency_subchain = subchain.frequency_filter(
        reference_sequence, lower, upper)</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.apply_statistics"><code class="name flex">
<span>def <span class="ident">apply_statistics</span></span>(<span>self, sequence:str=None) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Apply all statistics which were set beforehand.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_statistics(self, sequence: str = None) -&gt; None:
    &#34;&#34;&#34;
    Apply all statistics which were set beforehand.
    &#34;&#34;&#34;
    if sequence is None:
        sequence = self.current_sequence
    for name in self.statistics:
        function = eval(&#34;self.language_plugin.statistic_%s&#34; % (name))
        if (sequence, name) in self.stat_cache:
            self.statistics[name] = self.stat_cache[(sequence, name)]
        else:
            self.statistics[name] = function(self, sequence)
            self.stat_cache[(sequence, name)] = self.statistics[name]
        if &#39;match&#39; in function.__dict__:
            self.match_statistics[name] = function.match(
                self.statistics[name], self.reference_statistics[name])
        if &#39;difference&#39; in function.__dict__:
            self.difference_statistics[name] = function.difference(
                self.statistics[name], self.reference_statistics[name])</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.clear_attribute_filters"><code class="name flex">
<span>def <span class="ident">clear_attribute_filters</span></span>(<span>self) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Remove all set attribute filters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear_attribute_filters(self) -&gt; None:
    &#34;&#34;&#34;
    Remove all set attribute filters.
    &#34;&#34;&#34;
    self.attribute_filters = {}</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.clear_frequency_filter"><code class="name flex">
<span>def <span class="ident">clear_frequency_filter</span></span>(<span>self) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Clear the previously set frequency filter.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear_frequency_filter(self) -&gt; None:
    &#34;&#34;&#34;
    Clear the previously set frequency filter.
    &#34;&#34;&#34;
    self.frequency_filter = None
    self.frequency_subchain = None</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.clear_statistics"><code class="name flex">
<span>def <span class="ident">clear_statistics</span></span>(<span>self) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Clear all the statistics set previously.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear_statistics(self) -&gt; None:
    &#34;&#34;&#34;
    Clear all the statistics set previously.
    &#34;&#34;&#34;
    self.statistics = {}</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.download_language_plugin"><code class="name flex">
<span>def <span class="ident">download_language_plugin</span></span>(<span>self, language_plugin_name:str, path_to_save:str, auto_download=False) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Downloads and saves given language plugin to local storage from the corresponding official file repository.
This method is called when you load in a language plugin automatically.
If you need to ensure your Wuggy script works on any machine without user confirmation, execute this method with the</p>
<h2 id="parameters">Parameters</h2>
<p>language_plugin_name: this is the name for the official language plugin you want to download. If the language name is not officially supported, the method will throw an error.</p>
<p>path_to_save: absolute path to download the language plugin to.</p>
<p>auto_download: determines whether Wuggy provides the user with a prompt to confirm downloading a language plugin.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def download_language_plugin(
        self, language_plugin_name: str, path_to_save: str, auto_download=False) -&gt; None:
    &#34;&#34;&#34;
    Downloads and saves given language plugin to local storage from the corresponding official file repository.
    This method is called when you load in a language plugin automatically.
    If you need to ensure your Wuggy script works on any machine without user confirmation, execute this method with the
    Parameters:
        language_plugin_name: this is the name for the official language plugin you want to download. If the language name is not officially supported, the method will throw an error.

        path_to_save: absolute path to download the language plugin to.

        auto_download: determines whether Wuggy provides the user with a prompt to confirm downloading a language plugin.
    &#34;&#34;&#34;
    if language_plugin_name not in self.supported_official_language_plugin_names:
        raise ValueError(&#34;This language is not officially supported by Wuggy at this moment.&#34;)
    if not auto_download:
        while True:
            stdout.write(
                f&#34;The language plugin {language_plugin_name} was not found in local storage. Do you allow Wuggy to download this plugin? [y/n]\n&#34;)
            choice = input().lower()
            if (not (choice.startswith(&#34;y&#34;) or choice.startswith(&#34;n&#34;))):
                stdout.write(&#34;Please respond with &#39;y&#39; or &#39;n&#39;&#34;)
            elif choice.startswith(&#34;n&#34;):
                raise ValueError(
                    &#34;User declined permission for Wuggy to download necessary language plugin.&#34;)
            else:
                break
    warn(&#34;Wuggy is currently downloading this plugin for you from the official repository...&#34;)

    py_file_name = f&#34;{language_plugin_name}.py&#34;
    py_file = urlopen(
        f&#34;{self.__official_language_plugin_repository_url}/{language_plugin_name}/{py_file_name}&#34;)

    file = open(f&#39;{path_to_save}/{py_file_name}&#39;,
                &#39;w&#39;, encoding=&#34;utf-8&#34;)
    # The current setup assumes that every official Wuggy language plugin use a single data file
    for line in py_file:
        file.write(line.decode(&#34;utf-8&#34;))
    data_file_name = f&#34;{language_plugin_name}.txt&#34;
    data_file = urlopen(
        f&#34;{self.__official_language_plugin_repository_url}/{language_plugin_name}/{data_file_name}&#34;)
    file = open(f&#39;{path_to_save}/{data_file_name}&#39;,
                &#39;w&#39;, encoding=&#34;utf-8&#34;)

    for line in data_file:
        file.write(line.decode(&#34;utf-8&#34;))</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.export_classic_pseudoword_matches_to_csv"><code class="name flex">
<span>def <span class="ident">export_classic_pseudoword_matches_to_csv</span></span>(<span>self, pseudoword_matches:[typing.Dict], csv_path:str) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Helper function to export generated pseudoword matches from generate_classic to CSV.
The dictionairies from the matches are flattened before exporting to CSV.</p>
<h2 id="parameters">Parameters</h2>
<p>pseudoword_matches: a dictionary of pseudoword matches retrieved from generate_classic
csv_path: relative path to save csv file to (including the filename, e.g. ./pseudowords.csv)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def export_classic_pseudoword_matches_to_csv(
        self, pseudoword_matches: [Dict],
        csv_path: str) -&gt; None:
    &#34;&#34;&#34;
    Helper function to export generated pseudoword matches from generate_classic to CSV.
    The dictionairies from the matches are flattened before exporting to CSV.
    Parameters:

        pseudoword_matches: a dictionary of pseudoword matches retrieved from generate_classic
        csv_path: relative path to save csv file to (including the filename, e.g. ./pseudowords.csv)
    &#34;&#34;&#34;
    def get_csv_headers(dictionary: dict):
        headers = []

        def flatten_nested_dict_keys(dictionary: dict, parent_dict_key=None):
            for key, value in dictionary.items():
                key = str(key)
                if isinstance(value, dict):
                    flatten_nested_dict_keys(
                        value, (parent_dict_key + &#34;_&#34; + key if parent_dict_key else key))
                else:
                    if parent_dict_key:
                        headers.append((parent_dict_key + &#34;_&#34; + key))
                    else:
                        headers.append(key)
            return headers
        flatten_nested_dict_keys(dictionary)
        return headers

    def get_values_from_nested_dictionary(dictionary: dict):
        dict_vals = []

        def flatten_nested_dict_values(dictionary: dict):
            for value in dictionary.values():
                if isinstance(value, dict):
                    flatten_nested_dict_values(value)
                else:
                    dict_vals.append(value)
        flatten_nested_dict_values(dictionary)
        return dict_vals

    with open(csv_path, &#34;w&#34;, newline=&#39;&#39;) as csvfile:
        file_writer = writer(csvfile)
        file_writer.writerow(get_csv_headers(pseudoword_matches[0]))
        for match in pseudoword_matches:
            file_writer.writerow(get_values_from_nested_dictionary(match))</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.generate_advanced"><code class="name flex">
<span>def <span class="ident">generate_advanced</span></span>(<span>self, clear_cache:bool=True) >Union[Generator[str,NoneType,NoneType],Generator[tuple,NoneType,NoneType]]</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a custom generator which can be iterated to return generated pseudowords.
The generator's settings, such as output statistics, should be set by you before calling this method.
If attributes such as "output_mode" are not set, sensible defaults are used.
Note that this method is for advanced users and may result in unexpected results if handled incorrectly.</p>
<h1 id="generate-advanced-examples">Generate Advanced Examples</h1>
<h2 id="in-what-format-are-pseudowords-returned">In what format are pseudowords returned?</h2>
<p>Using the advanced generate method, Wuggy will return a generator which you can iterate over to generate pseudowords, e.g:</p>
<pre><code class="language-python">from wuggy import WuggyGenerator

g = WuggyGenerator()
g.load(&quot;orthographic_english&quot;)
g.set_reference_sequence(&quot;balloon&quot;)
for sequence in g.generate_advanced(clear_cache=False):
    print(sequence)
</code></pre>
<p>(note that this example returns rather useless pseudowords since there are no restrictions set)</p>
<h2 id="generating-pseudowords-with-sensible-settings">Generating Pseudowords (with sensible settings)</h2>
<p>Generating pseudowords using this method requires good knowledge of Wuggy in order to generate pseudowords which, for example, closely resemble the origin reference word.</p>
<p>The following example uses advanced generation to set a number of restrictions on generated pseudowords.</p>
<ol>
<li>Each origin word will generate a maximum of 10 pseudowords</li>
<li>Each pseudoword must be a non-word</li>
<li>Each pseudoword must overlap 2/3 subsyllabic segments</li>
<li>The frequency filter is increased if not enough matches are found within a given band (this is concentric search)</li>
<li>Sensible attribute filters are enforced</li>
</ol>
<pre><code class="language-python">from fractions import Fraction

from wuggy import WuggyGenerator

words = [&quot;trumpet&quot;, &quot;car&quot;]
g = WuggyGenerator()
g.load(&quot;orthographic_english&quot;)
ncandidates = 10
for word in words:
    g.set_reference_sequence(g.lookup_reference_segments(word))
    g.set_attribute_filter('sequence_length')
    g.set_attribute_filter('segment_length')
    g.set_statistic('overlap_ratio')
    g.set_statistic('plain_length')
    g.set_statistic('transition_frequencies')
    g.set_statistic('lexicality')
    g.set_statistic('ned1')
    g.set_output_mode('syllabic')
    j = 0
    for i in range(1, 10, 1):
        g.set_frequency_filter(2**i, 2**i)
        for sequence in g.generate_advanced(clear_cache=False):
            match = False
            if (g.statistics['overlap_ratio'] == Fraction(2, 3) and
                    g.statistics['lexicality'] == &quot;N&quot;):
                match = True
            if match == True:
                print(sequence)
                j = j+1
                if j &gt; ncandidates:
                    break
        if j &gt; ncandidates:
            break
</code></pre>
<p>Note how using <code>generate_advanced</code> requires setting many parameters and candidate check logic yourself.
Make sure that <code>generate_classic</code> does not suit your needs before using this method, as its low level nature makes it easy to return pseudowords which do not fit your needs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@_loaded_language_plugin_required_generator
def generate_advanced(self, clear_cache: bool = True) -&gt; Union[Generator[str, None, None],
                                                               Generator[tuple, None, None]]:
    &#34;&#34;&#34;
    Creates a custom generator which can be iterated to return generated pseudowords.
    The generator&#39;s settings, such as output statistics, should be set by you before calling this method.
    If attributes such as \&#34;output_mode\&#34; are not set, sensible defaults are used.
    Note that this method is for advanced users and may result in unexpected results if handled incorrectly.
    .. include:: ../../documentation/wuggygenerator/generate_advanced.md
    &#34;&#34;&#34;
    if clear_cache:
        self.__clear_sequence_cache()
    if self.output_mode is None:
        self.set_output_mode(&#34;plain&#34;)
    if len(self.attribute_filters) == 0 and self.frequency_subchain is None:
        subchain = self.bigramchain
    if len(self.attribute_filters) != 0:
        if self.attribute_subchain is None:
            self.__apply_attribute_filters()
        subchain = self.attribute_subchain
    if self.frequency_filter is not None:
        self.apply_frequency_filter()
        subchain = self.frequency_subchain
    if self.reference_sequence is not None:
        subchain = subchain.clean(len(self.reference_sequence) - 1)
        subchain.set_startkeys(self.reference_sequence)
    else:
        warn(
            &#34;No reference sequence was set. Ignore this message if this was intentional.&#34;)
        subchain.set_startkeys()
    for sequence in subchain.generate():
        if self.language_plugin.output_plain(sequence) in self.sequence_cache:
            pass
        else:
            self.sequence_cache.append(
                self.language_plugin.output_plain(sequence))
            self.current_sequence = sequence
            self.apply_statistics()
            yield self.output_mode(sequence)</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.generate_classic"><code class="name flex">
<span>def <span class="ident">generate_classic</span></span>(<span>self, input_sequences:[<class'str'>], ncandidates_per_sequence:int=10, max_search_time_per_sequence:int=10, subsyllabic_segment_overlap_ratio:Union[fractions.Fraction,NoneType]=Fraction(2, 3), match_subsyllabic_segment_length:bool=True, match_letter_length:bool=True, output_mode:str='plain', concentric_search:bool=True) >[typing.Dict]</span>
</code></dt>
<dd>
<div class="desc"><p>This is the classic method to generate pseudowords using Wuggy and can be called immediately after loading a language plugin.
The defaults for this method are similar to those set in the legacy version of Wuggy, resulting in sensible pseudowords.
This method returns a list of pseudoword matches, including all match and difference statistics (lexicality, ned1, old2, plain_length, deviation statistics&hellip;).
Beware that this method always clears the sequence cache and all previously set filters.</p>
<h2 id="parameters">Parameters</h2>
<p>input_sequences: these are the input sequences (words) for which you want to generate pseudowords.</p>
<p>ncandidates_per_sequence: this is the n (maximum) amount of pseudowords you want to generate per input sequence.</p>
<p>max_search_time_per_sequence: this is the maximum time in seconds to search for pseudowords per input sequence.</p>
<p>subsyllabic_segment_overlap_ratio: this is the Fraction ratio for overlap between subsyllabic segments. The default ensures your pseudowords are very word-like but not easily identifiable as related to an existing word. If set to None, this constraint is not applied.</p>
<p>match_subsyllabic_segment_length: determines whether the generated pseudowords must retain the same subsyllabic segment length as the respective input sequence.</p>
<p>match_letter_length: determines whether the generated pseudowords must retain the same word length as the respective input sequence. This option is redundant if match_subsyllabic_segment_length is set to True.</p>
<p>output_mode: output mode for pseudowords, constricted by the output modes supported by the currently loaded language plugin.</p>
<p>concentric_search: enable/disable concentric search. Wuggy operates best and fastest when concentric search is enabled. First, the algorithm will try to generate candidates that exactly match the transition frequencies of the reference word. Then the maximal allowed deviation in transition frequencies will increase by powers of 2 (i.e., +/-2, +/-4, +/-8, etc.).</p>
<h1 id="generate-classic-examples">Generate Classic Examples</h1>
<h2 id="in-what-format-are-pseudowords-returned">In what format are pseudowords returned?</h2>
<p>Pseudowords are returned in a dictionary format in a verbose format, containing details such as statistics. Below is an example return value for a pseudoword generated for <code>car</code>.</p>
<pre><code class="language-python">{
    &quot;word&quot;: &quot;car&quot;,
    &quot;segments&quot;: &quot;car&quot;,
    &quot;pseudoword&quot;: &quot;cag&quot;,
    &quot;statistics&quot;: {
        &quot;lexicality&quot;: &quot;N&quot;,
        &quot;ned1&quot;: 24,
        &quot;old20&quot;: 1.0,
        &quot;overlap&quot;: 2,
        &quot;overlap_ratio&quot;: Fraction(2, 3),
        &quot;plain_length&quot;: 1,
        &quot;transition_frequencies&quot;: {0: 304, 1: 92, 2: 22, 3: 80},
    },
    &quot;difference_statistics&quot;: {
        &quot;ned1&quot;: -4,
        &quot;old20&quot;: 0.050000000000000044,
        &quot;plain_length&quot;: 0,
        &quot;transition_frequencies&quot;: {0: 0, 1: 0, 2: 8, 3: -11},
    },
}
</code></pre>
<h2 id="generating-pseudowords-default-settings">Generating pseudowords (default settings)</h2>
<p>In this example, we will generate pseudowords for the English words <code>car</code> and <code>bicycle</code>. We will print these pseudowords to the console.</p>
<pre><code class="language-python">from wuggy import WuggyGenerator

g = WuggyGenerator()
g.load(&quot;orthographic_english&quot;)
for match in g.generate_classic([&quot;car&quot;, &quot;bicycle&quot;]):
    print(match[&quot;pseudoword&quot;])
</code></pre>
<p>The code above first loads the <code>orthographic_english</code> language plugin. After this, the <code>generate_classic</code> method is called with a list of reference sequences for which we want to generate pseudowords. The method returns a list of pseudoword matches. These matches consist of dictionairies with many details about the match, such as relevant statistics. Since we are only interested in the generated pseudowords, we print the value assigned to the key <code>pseudoword</code>. </p>
<h2 id="generating-pseudowords-custom-settings">Generating pseudowords (custom settings)</h2>
<p>In this example, we will generate pseudowords for the English words <code>car</code> and <code>bicycle</code>, this time using some custom settings. The <code>generate_classic</code> method takes several optional arguments which can be used to change the output of the generator. The defaults are usually great for generating useful pseudowords, so this example will only change two parameters. </p>
<pre><code class="language-python">from wuggy import WuggyGenerator

g = WuggyGenerator()
g.load(&quot;orthographic_english&quot;)
for match in g.generate_classic(
    [&quot;car&quot;, &quot;bicycle&quot;],
    ncandidates_per_sequence=30, max_search_time_per_sequence=25):
    print(match[&quot;pseudoword&quot;])
</code></pre>
<p>The code above will ensure that, per sequence in the input list, a maximum of 30 candidates will be generated. By default, Wuggy only has 10 seconds to find this amount of candidates per sequence. For this reason, we can set the <code>max_search_time_per_sequence</code> to a higher amount to ensure that 30 sequences can be generated in time.</p>
<h2 id="generating-pseudowords-and-exporting-to-csv">Generating pseudowords and exporting to CSV</h2>
<p>Since Wuggy is a Python library, its output can be easily used by other modules to perform actions such as exporting pseudowords to CSV. This can be done manually, although Wuggy includes a built-in helper method to easily export classic pseudoword matches to a CSV file:</p>
<pre><code class="language-python">from csv import DictWriter

from wuggy.generators.wuggygenerator import WuggyGenerator

g = WuggyGenerator()
g.load(&quot;orthographic_english&quot;)
pseudoword_matches = g.generate_classic([&quot;car&quot;])
g.export_classic_pseudoword_matches_to_csv(pseudoword_matches, &quot;./pseudowords.csv&quot;)
</code></pre>
<p>By using this method, the nested dictionary will be flattened so that the resulting CSV can be easily interpreted by your software of choice.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@_loaded_language_plugin_required
def generate_classic(
        self, input_sequences: [str],
        ncandidates_per_sequence: int = 10, max_search_time_per_sequence: int = 10,
        subsyllabic_segment_overlap_ratio: Union[Fraction, None] = Fraction(2, 3),
        match_subsyllabic_segment_length: bool = True, match_letter_length: bool = True,
        output_mode: str = &#34;plain&#34;, concentric_search: bool = True) -&gt; [Dict]:
    &#34;&#34;&#34;
    This is the classic method to generate pseudowords using Wuggy and can be called immediately after loading a language plugin.
    The defaults for this method are similar to those set in the legacy version of Wuggy, resulting in sensible pseudowords.
    This method returns a list of pseudoword matches, including all match and difference statistics (lexicality, ned1, old2, plain_length, deviation statistics...).
    Beware that this method always clears the sequence cache and all previously set filters.
    Parameters:
        input_sequences: these are the input sequences (words) for which you want to generate pseudowords.

        ncandidates_per_sequence: this is the n (maximum) amount of pseudowords you want to generate per input sequence.

        max_search_time_per_sequence: this is the maximum time in seconds to search for pseudowords per input sequence.

        subsyllabic_segment_overlap_ratio: this is the Fraction ratio for overlap between subsyllabic segments. The default ensures your pseudowords are very word-like but not easily identifiable as related to an existing word. If set to None, this constraint is not applied.

        match_subsyllabic_segment_length: determines whether the generated pseudowords must retain the same subsyllabic segment length as the respective input sequence.

        match_letter_length: determines whether the generated pseudowords must retain the same word length as the respective input sequence. This option is redundant if match_subsyllabic_segment_length is set to True.

        output_mode: output mode for pseudowords, constricted by the output modes supported by the currently loaded language plugin.

        concentric_search: enable/disable concentric search. Wuggy operates best and fastest when concentric search is enabled. First, the algorithm will try to generate candidates that exactly match the transition frequencies of the reference word. Then the maximal allowed deviation in transition frequencies will increase by powers of 2 (i.e., +/-2, +/-4, +/-8, etc.).
    .. include:: ../../documentation/wuggygenerator/generate_classic.md
    &#34;&#34;&#34;
    pseudoword_matches = []
    for input_sequence in input_sequences:
        pseudoword_matches.extend(
            self.__generate_classic_inner(
                input_sequence,
                ncandidates_per_sequence,
                max_search_time_per_sequence,
                subsyllabic_segment_overlap_ratio,
                match_subsyllabic_segment_length,
                match_letter_length, output_mode, concentric_search))
    return pseudoword_matches</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.get_limit_frequencies"><code class="name flex">
<span>def <span class="ident">get_limit_frequencies</span></span>(<span>self, fields)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_limit_frequencies(self, fields):
    # TODO: docstring and parameter type hint
    limits = []
    if tuple(fields) not in self.bigramchain.limit_frequencies:
        self.bigramchain.build_limit_frequencies(fields)
    for i in range(0, len(self.reference_sequence) - 1):
        subkey_a = (i, tuple(
            [self.reference_sequence[i].__getattribute__(field) for field in fields]))
        subkey_b = (i + 1,
                    tuple(
                        [self.reference_sequence[i + 1].__getattribute__(field)
                         for field in fields]))
        subkey = (subkey_a, subkey_b)
        try:
            limits.append(
                self.bigramchain.limit_frequencies[tuple(fields)][subkey])
        except BaseException:
            limits.append([{max: 0, min: 0}])
    return limits</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.list_output_modes"><code class="name flex">
<span>def <span class="ident">list_output_modes</span></span>(<span>self) >[<class'str'>]</span>
</code></dt>
<dd>
<div class="desc"><p>List output modes of the currently activated language plugin.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def list_output_modes(self) -&gt; [str]:
    &#34;&#34;&#34;
    List output modes of the currently activated language plugin.
    &#34;&#34;&#34;
    names = [name for name in dir(
        self.language_plugin) if name.startswith(&#39;output&#39;)]
    return [name.replace(&#39;output_&#39;, &#39;&#39;) for name in names]</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>self, language_plugin_name:str, local_language_plugin:<a title="wuggy.plugins.baselanguageplugin.BaseLanguagePlugin" href="../plugins/baselanguageplugin.html#wuggy.plugins.baselanguageplugin.BaseLanguagePlugin">BaseLanguagePlugin</a>=None) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Loads in a language plugin, if available, and stores the corresponding bigramchains.</p>
<h2 id="parameters">Parameters</h2>
<p>language_plugin_name: must be the exact string of an official language plugin (see self.supported_official_language_plugin_names). If you are loading in a local plugin, the name can be anything as long as it does not conflict with an already loaded plugin name.</p>
<p>local_language_plugin: must be a child class of BaseLanguagePlugin: see BaseLanguagePlugin for more information on how to create a custom language plugin.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load(self, language_plugin_name: str,
         local_language_plugin: BaseLanguagePlugin = None) -&gt; None:
    &#34;&#34;&#34;
    Loads in a language plugin, if available, and stores the corresponding bigramchains.
    Parameters:
        language_plugin_name: must be the exact string of an official language plugin (see self.supported_official_language_plugin_names). If you are loading in a local plugin, the name can be anything as long as it does not conflict with an already loaded plugin name.

        local_language_plugin: must be a child class of BaseLanguagePlugin: see BaseLanguagePlugin for more information on how to create a custom language plugin.
    &#34;&#34;&#34;
    if local_language_plugin:
        # TODO: if someone does not pass a class INSTANCE, they get TypeError: &lt;class &#39;type&#39;&gt; is a built-in class, this is a vague error and probably should be abstracted
        self.language_plugin_data_path = os.path.dirname(
            inspect.getfile(local_language_plugin.__class__))
        self.language_plugin_name = language_plugin_name
        language_plugin = local_language_plugin

    if local_language_plugin is None:
        if language_plugin_name not in self.supported_official_language_plugin_names:
            raise ValueError(
                &#34;This language is not officially supported by Wuggy at this moment. If this is a local plugin, pass the local_language_plugin&#34;)
        self.language_plugin_name = language_plugin_name
        language_plugins_folder_dirname = os.path.join(
            Path(__file__).parents[1], &#34;plugins&#34;, &#34;language_data&#34;)
        # TODO: move these os path checks under download method, only if autodownload is off
        if not os.path.exists(language_plugins_folder_dirname):
            os.makedirs(language_plugins_folder_dirname)
        self.language_plugin_data_path = os.path.join(
            language_plugins_folder_dirname, language_plugin_name)
        if not os.path.exists(self.language_plugin_data_path):
            os.makedirs(self.language_plugin_data_path)
            self.download_language_plugin(
                language_plugin_name, self.language_plugin_data_path)
        # Official language plugins MUST have the class name &#34;OfficialLanguagePlugin&#34;!
        language_plugin = importlib.import_module(
            f&#34;.plugins.language_data.{language_plugin_name}.{language_plugin_name}&#34;,
            &#34;wuggy&#34;).OfficialLanguagePlugin()

    if language_plugin_name not in self.bigramchains:
        default_data_path = os.path.join(
            self.language_plugin_data_path, language_plugin.default_data)

        data_file = codecs.open(default_data_path, &#39;r&#39;, encoding=&#39;utf-8&#39;)
        self.bigramchains[self.language_plugin_name] = BigramChain(
            language_plugin)
        self.bigramchains[self.language_plugin_name].load(
            data_file)
    self.__activate(self.language_plugin_name)</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.lookup_reference_segments"><code class="name flex">
<span>def <span class="ident">lookup_reference_segments</span></span>(<span>self, reference:str) >Union[str,NoneType]</span>
</code></dt>
<dd>
<div class="desc"><p>Look up a given reference (word) from the currently active lookup lexicon.
Returns the segments of the found word, if the word is not found it returns None.
This should be used before setting a word as a reference sequence.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lookup_reference_segments(self, reference: str) -&gt; Optional[str]:
    &#34;&#34;&#34;
    Look up a given reference (word) from the currently active lookup lexicon.
    Returns the segments of the found word, if the word is not found it returns None.
    This should be used before setting a word as a reference sequence.
    &#34;&#34;&#34;
    return self.lookup_lexicon.get(reference, None)</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.set_all_statistics"><code class="name flex">
<span>def <span class="ident">set_all_statistics</span></span>(<span>self) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Enable all statistics supported by the current active language plugin.
Enabling all statistics increases word generation computation time, especially for statistics such as ned1.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_all_statistics(self) -&gt; None:
    &#34;&#34;&#34;
    Enable all statistics supported by the current active language plugin.
    Enabling all statistics increases word generation computation time, especially for statistics such as ned1.
    &#34;&#34;&#34;
    self.set_statistics(self.supported_statistics)</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.set_attribute_filter"><code class="name flex">
<span>def <span class="ident">set_attribute_filter</span></span>(<span>self, name:str) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Set an attribute filter supported by the currently activated language plugin.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_attribute_filter(self, name: str) -&gt; None:
    &#34;&#34;&#34;
    Set an attribute filter supported by the currently activated language plugin.
    &#34;&#34;&#34;
    reference_sequence = self.reference_sequence
    if name not in self.supported_attribute_filters:
        raise ValueError(
            f&#34;Attribute filter {name} is not supported.&#34;)
    self.attribute_filters[name] = reference_sequence
    self.attribute_subchain = None</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.set_attribute_filters"><code class="name flex">
<span>def <span class="ident">set_attribute_filters</span></span>(<span>self, names:[<class'str'>]) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Set attribute filters supported by the currently activated language plugin.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_attribute_filters(self, names: [str]) -&gt; None:
    &#34;&#34;&#34;
    Set attribute filters supported by the currently activated language plugin.
    &#34;&#34;&#34;
    for name in names:
        self.set_attribute_filter(name)</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.set_frequency_filter"><code class="name flex">
<span>def <span class="ident">set_frequency_filter</span></span>(<span>self, lower:int, upper:int) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the frequency filter for concentric search.
Stricter search (small values for lower and upper) result in faster word generation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_frequency_filter(self, lower: int, upper: int) -&gt; None:
    &#34;&#34;&#34;
    Sets the frequency filter for concentric search.
    Stricter search (small values for lower and upper) result in faster word generation.
    &#34;&#34;&#34;
    self.frequency_filter = (self.reference_sequence, lower, upper)</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.set_output_mode"><code class="name flex">
<span>def <span class="ident">set_output_mode</span></span>(<span>self, name:str) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Set an output mode supported by the currently activated language plugin.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_output_mode(self, name: str) -&gt; None:
    &#34;&#34;&#34;
    Set an output mode supported by the currently activated language plugin.
    &#34;&#34;&#34;
    if name not in self.list_output_modes():
        raise ValueError(f&#34;Output mode {name} is not supported.&#34;)
    self.output_mode = eval(&#34;self.language_plugin.output_%s&#34; % (name))</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.set_reference_sequence"><code class="name flex">
<span>def <span class="ident">set_reference_sequence</span></span>(<span>self, sequence:str) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Set the reference sequence.
This is commonly used before generate methods in order to set the reference word for which pseudowords should be generated.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@_loaded_language_plugin_required
def set_reference_sequence(self, sequence: str) -&gt; None:
    &#34;&#34;&#34;
    Set the reference sequence.
    This is commonly used before generate methods in order to set the reference word for which pseudowords should be generated.
    &#34;&#34;&#34;
    self.reference_sequence = self.language_plugin.transform(
        sequence).representation
    self.reference_sequence_frequencies = self.bigramchain.get_frequencies(
        self.reference_sequence)
    self.__clear_stat_cache()
    for name in self.__get_statistics():
        function = eval(&#34;self.language_plugin.statistic_%s&#34; % (name))
        self.reference_statistics[name] = function(
            self, self.reference_sequence)</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.set_statistic"><code class="name flex">
<span>def <span class="ident">set_statistic</span></span>(<span>self, name:str) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Enable a statistic based on its name.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_statistic(self, name: str) -&gt; None:
    &#34;&#34;&#34;
    Enable a statistic based on its name.
    &#34;&#34;&#34;
    if name not in self.supported_statistics:
        raise ValueError(f&#34;Statistic {name} is not supported.&#34;)
    self.statistics[name] = None</code></pre>
</details>
</dd>
<dt id="wuggy.generators.wuggygenerator.WuggyGenerator.set_statistics"><code class="name flex">
<span>def <span class="ident">set_statistics</span></span>(<span>self, names:[<class'str'>]) >NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Enables statistics based on their names.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_statistics(self, names: [str]) -&gt; None:
    &#34;&#34;&#34;
    Enables statistics based on their names.
    &#34;&#34;&#34;
    for name in names:
        if name not in self.supported_statistics:
            self.statistics = {}
            raise ValueError(f&#34;Statistic {name} is not supported.&#34;)
        self.statistics[name] = None</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<h2><a href="/wuggy">Wuggy Documentation</a></h2>
<a class="homelink" rel="home" title="Wuggy Home" href="https://github.com/Zenulous/wuggy/">
<img src="https://raw.githubusercontent.com/Zenulous/wuggy/master/assets/wuggyIcon.jpg" width="35%" alt="Wuggy Logo">
</a>
<h1>Quickstarts</h1>
<p><a href="/wuggy/generators/wuggygenerator.html#generate-classic-examples" title="generate-pseudowords">Easily generate pseudowords</a></p>
<p><a href="/wuggy/plugins/baselanguageplugin.html#creating-a-custom-language-plugin" title="create-language-plugin">Create a custom language plugin</a></p>
<p><a href="/wuggy/evaluators/index.html" title="evaluate-pseudowords">Evaluate pseudowords</a></p>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="wuggy.generators" href="index.html">wuggy.generators</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator" href="#wuggy.generators.wuggygenerator.WuggyGenerator">WuggyGenerator</a></code></h4>
<ul class="">
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.apply_frequency_filter" href="#wuggy.generators.wuggygenerator.WuggyGenerator.apply_frequency_filter">apply_frequency_filter</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.apply_statistics" href="#wuggy.generators.wuggygenerator.WuggyGenerator.apply_statistics">apply_statistics</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.clear_attribute_filters" href="#wuggy.generators.wuggygenerator.WuggyGenerator.clear_attribute_filters">clear_attribute_filters</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.clear_frequency_filter" href="#wuggy.generators.wuggygenerator.WuggyGenerator.clear_frequency_filter">clear_frequency_filter</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.clear_statistics" href="#wuggy.generators.wuggygenerator.WuggyGenerator.clear_statistics">clear_statistics</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.download_language_plugin" href="#wuggy.generators.wuggygenerator.WuggyGenerator.download_language_plugin">download_language_plugin</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.export_classic_pseudoword_matches_to_csv" href="#wuggy.generators.wuggygenerator.WuggyGenerator.export_classic_pseudoword_matches_to_csv">export_classic_pseudoword_matches_to_csv</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.generate_advanced" href="#wuggy.generators.wuggygenerator.WuggyGenerator.generate_advanced">generate_advanced</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.generate_classic" href="#wuggy.generators.wuggygenerator.WuggyGenerator.generate_classic">generate_classic</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.get_limit_frequencies" href="#wuggy.generators.wuggygenerator.WuggyGenerator.get_limit_frequencies">get_limit_frequencies</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.list_output_modes" href="#wuggy.generators.wuggygenerator.WuggyGenerator.list_output_modes">list_output_modes</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.load" href="#wuggy.generators.wuggygenerator.WuggyGenerator.load">load</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.lookup_reference_segments" href="#wuggy.generators.wuggygenerator.WuggyGenerator.lookup_reference_segments">lookup_reference_segments</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.remove_downloaded_language_plugins" href="#wuggy.generators.wuggygenerator.WuggyGenerator.remove_downloaded_language_plugins">remove_downloaded_language_plugins</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.set_all_statistics" href="#wuggy.generators.wuggygenerator.WuggyGenerator.set_all_statistics">set_all_statistics</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.set_attribute_filter" href="#wuggy.generators.wuggygenerator.WuggyGenerator.set_attribute_filter">set_attribute_filter</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.set_attribute_filters" href="#wuggy.generators.wuggygenerator.WuggyGenerator.set_attribute_filters">set_attribute_filters</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.set_frequency_filter" href="#wuggy.generators.wuggygenerator.WuggyGenerator.set_frequency_filter">set_frequency_filter</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.set_output_mode" href="#wuggy.generators.wuggygenerator.WuggyGenerator.set_output_mode">set_output_mode</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.set_reference_sequence" href="#wuggy.generators.wuggygenerator.WuggyGenerator.set_reference_sequence">set_reference_sequence</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.set_statistic" href="#wuggy.generators.wuggygenerator.WuggyGenerator.set_statistic">set_statistic</a></code></li>
<li><code><a title="wuggy.generators.wuggygenerator.WuggyGenerator.set_statistics" href="#wuggy.generators.wuggygenerator.WuggyGenerator.set_statistics">set_statistics</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>